{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "consecutive-preparation",
   "metadata": {
    "papermill": {
     "duration": 0.022996,
     "end_time": "2021-05-01T13:34:16.895209",
     "exception": false,
     "start_time": "2021-05-01T13:34:16.872213",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Directory settiings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acquired-static",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-01T13:34:16.946824Z",
     "iopub.status.busy": "2021-05-01T13:34:16.946012Z",
     "iopub.status.idle": "2021-05-01T13:34:16.950599Z",
     "shell.execute_reply": "2021-05-01T13:34:16.950012Z"
    },
    "papermill": {
     "duration": 0.033484,
     "end_time": "2021-05-01T13:34:16.950772",
     "exception": false,
     "start_time": "2021-05-01T13:34:16.917288",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Directory settings\n",
    "# ====================================================\n",
    "import os\n",
    "\n",
    "OUTPUT_DIR='./'\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR)\n",
    "    \n",
    "ROOT_DIR = '../input/shopee-product-matching/'\n",
    "TRAIN_PATH = ROOT_DIR + 'train_images/'\n",
    "TEST_PATH = ROOT_DIR + 'test_images/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fantastic-shopping",
   "metadata": {
    "papermill": {
     "duration": 0.021737,
     "end_time": "2021-05-01T13:34:16.994408",
     "exception": false,
     "start_time": "2021-05-01T13:34:16.972671",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## CFG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "damaged-cooling",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-01T13:34:17.045817Z",
     "iopub.status.busy": "2021-05-01T13:34:17.044834Z",
     "iopub.status.idle": "2021-05-01T13:34:17.048117Z",
     "shell.execute_reply": "2021-05-01T13:34:17.047602Z"
    },
    "papermill": {
     "duration": 0.031899,
     "end_time": "2021-05-01T13:34:17.048323",
     "exception": false,
     "start_time": "2021-05-01T13:34:17.016424",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# CFG\n",
    "# ====================================================\n",
    "class CFG:\n",
    "    debug = False\n",
    "    CHECK_SUB = False\n",
    "    GET_CV = True\n",
    "    num_workers = 4\n",
    "    model_name_cnn = 'seresnet152d'\n",
    "    model_name_bert = '../input/sentence-transformer-models/paraphrase-xlm-r-multilingual-v1/0_Transformer'\n",
    "    size = 512\n",
    "    batch_size = 32\n",
    "    seed = 42\n",
    "    target_size = 8811\n",
    "    target_size_list = [8811, 8812, 8811, 8811, 8811]\n",
    "    target_col = 'label_group'\n",
    "    scale = 30\n",
    "    margin = 0.5\n",
    "    fc_dim = 512\n",
    "    n_fold = 5\n",
    "    trn_fold = [0]\n",
    "    train = False\n",
    "    inference = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "clean-scanning",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-01T13:34:17.099819Z",
     "iopub.status.busy": "2021-05-01T13:34:17.099200Z",
     "iopub.status.idle": "2021-05-01T13:34:17.114959Z",
     "shell.execute_reply": "2021-05-01T13:34:17.114301Z"
    },
    "papermill": {
     "duration": 0.043745,
     "end_time": "2021-05-01T13:34:17.115134",
     "exception": false,
     "start_time": "2021-05-01T13:34:17.071389",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this submission notebook will compute CV score, but commit notebook will not\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "test = pd.read_csv('../input/shopee-product-matching/test.csv')\n",
    "if len(test)>3: \n",
    "    CFG.GET_CV = False\n",
    "else: \n",
    "    print('this submission notebook will compute CV score, but commit notebook will not')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worldwide-gateway",
   "metadata": {
    "papermill": {
     "duration": 0.022074,
     "end_time": "2021-05-01T13:34:17.160342",
     "exception": false,
     "start_time": "2021-05-01T13:34:17.138268",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "primary-coating",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-01T13:34:17.217992Z",
     "iopub.status.busy": "2021-05-01T13:34:17.217111Z",
     "iopub.status.idle": "2021-05-01T13:34:26.545879Z",
     "shell.execute_reply": "2021-05-01T13:34:26.544336Z"
    },
    "papermill": {
     "duration": 9.362573,
     "end_time": "2021-05-01T13:34:26.546024",
     "exception": false,
     "start_time": "2021-05-01T13:34:17.183451",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Library\n",
    "# ====================================================\n",
    "import sys\n",
    "sys.path.append('../input/timm-pytorch-image-models/pytorch-image-models-master')\n",
    "\n",
    "import os\n",
    "import math\n",
    "import time\n",
    "import random\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from contextlib import contextmanager\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from functools import partial\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam, SGD\n",
    "import torchvision.models as models\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, CosineAnnealingLR, ReduceLROnPlateau, _LRScheduler\n",
    "\n",
    "import transformers\n",
    "\n",
    "from albumentations import (\n",
    "    Compose, OneOf, Normalize, Resize, RandomResizedCrop, RandomCrop, HorizontalFlip, VerticalFlip, \n",
    "    RandomBrightness, RandomContrast, RandomBrightnessContrast, Rotate, ShiftScaleRotate, Cutout, \n",
    "    IAAAdditiveGaussianNoise, Transpose\n",
    "    )\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from albumentations import ImageOnlyTransform\n",
    "\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import cudf\n",
    "import cuml\n",
    "import cupy\n",
    "from cuml.feature_extraction.text import TfidfVectorizer\n",
    "from cuml import PCA\n",
    "from cuml.neighbors import NearestNeighbors\n",
    "\n",
    "import timm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "peripheral-dublin",
   "metadata": {
    "papermill": {
     "duration": 0.022302,
     "end_time": "2021-05-01T13:34:26.591724",
     "exception": false,
     "start_time": "2021-05-01T13:34:26.569422",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "adjustable-juvenile",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-01T13:34:26.649156Z",
     "iopub.status.busy": "2021-05-01T13:34:26.648321Z",
     "iopub.status.idle": "2021-05-01T13:34:28.960056Z",
     "shell.execute_reply": "2021-05-01T13:34:28.958780Z"
    },
    "papermill": {
     "duration": 2.345871,
     "end_time": "2021-05-01T13:34:28.960235",
     "exception": false,
     "start_time": "2021-05-01T13:34:26.614364",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Utils\n",
    "# ====================================================\n",
    "def f1_score(y_true, y_pred):\n",
    "    y_true = y_true.apply(lambda x: set(x.split()))\n",
    "    y_pred = y_pred.apply(lambda x: set(x.split()))\n",
    "    intersection = np.array([len(x[0] & x[1]) for x in zip(y_true, y_pred)])\n",
    "    len_y_pred = y_pred.apply(lambda x: len(x)).values\n",
    "    len_y_true = y_true.apply(lambda x: len(x)).values\n",
    "    f1 = 2 * intersection / (len_y_pred + len_y_true)\n",
    "    return f1\n",
    "\n",
    "def combine_predictions(row):\n",
    "    x = np.concatenate([row['image_predictions'], row['text_predictions']])\n",
    "    return ' '.join( np.unique(x) )\n",
    "\n",
    "@contextmanager\n",
    "def timer(name):\n",
    "    t0 = time.time()\n",
    "    LOGGER.info(f'[{name}] start')\n",
    "    yield\n",
    "    LOGGER.info(f'[{name}] done in {time.time() - t0:.0f} s.')\n",
    "\n",
    "def init_logger(log_file=OUTPUT_DIR+'inference.log'):\n",
    "    from logging import getLogger, INFO, FileHandler,  Formatter,  StreamHandler\n",
    "    logger = getLogger(__name__)\n",
    "    logger.setLevel(INFO)\n",
    "    handler1 = StreamHandler()\n",
    "    handler1.setFormatter(Formatter(\"%(message)s\"))\n",
    "    handler2 = FileHandler(filename=log_file)\n",
    "    handler2.setFormatter(Formatter(\"%(message)s\"))\n",
    "    logger.addHandler(handler1)\n",
    "    logger.addHandler(handler2)\n",
    "    return logger\n",
    "\n",
    "#LOGGER = init_logger()\n",
    "\n",
    "def seed_torch(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "seed_torch(seed=CFG.seed)\n",
    "\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(CFG.model_name_bert)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exempt-intersection",
   "metadata": {
    "papermill": {
     "duration": 0.023417,
     "end_time": "2021-05-01T13:34:29.007290",
     "exception": false,
     "start_time": "2021-05-01T13:34:28.983873",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "chinese-drilling",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-01T13:34:29.068448Z",
     "iopub.status.busy": "2021-05-01T13:34:29.066396Z",
     "iopub.status.idle": "2021-05-01T13:34:29.071884Z",
     "shell.execute_reply": "2021-05-01T13:34:29.071398Z"
    },
    "papermill": {
     "duration": 0.041611,
     "end_time": "2021-05-01T13:34:29.072009",
     "exception": false,
     "start_time": "2021-05-01T13:34:29.030398",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_dataset():\n",
    "    if CFG.GET_CV:\n",
    "        \n",
    "        # create folds\n",
    "        # trainingの時と同じようにfoldを切っています。\n",
    "        folds = pd.read_csv('../input/shopee-product-matching/train.csv')\n",
    "        if CFG.debug:\n",
    "            folds = folds.sample(n=3000, random_state=CFG.seed).reset_index(drop=True)  \n",
    "        Fold = GroupKFold(n_splits=CFG.n_fold)\n",
    "        groups = folds['label_group'].values\n",
    "        for n, (train_index, val_index) in enumerate(Fold.split(folds, folds[CFG.target_col], groups)):\n",
    "            folds.loc[val_index, 'fold'] = int(n)\n",
    "        folds['fold'] = folds['fold'].astype(int)\n",
    "        display(folds.groupby('fold').size())\n",
    "        \n",
    "        tmp = folds.groupby('label_group')['posting_id'].unique().to_dict()\n",
    "        folds['matches'] = folds['label_group'].map(tmp)\n",
    "        folds['matches'] = folds['matches'].apply(lambda x: ' '.join(x))\n",
    "        folds['file_path'] = folds['image'].apply(lambda x: TRAIN_PATH + x)\n",
    "        \n",
    "        if CFG.CHECK_SUB:\n",
    "            folds = pd.concat([folds, folds], axis=0)\n",
    "            folds.reset_index(drop=True, inplace=True)\n",
    "        folds_cu = cudf.DataFrame(folds)\n",
    "    else:\n",
    "        folds = pd.read_csv('../input/shopee-product-matching/test.csv')\n",
    "        folds['file_path'] = folds['image'].apply(lambda x: TEST_PATH + x)\n",
    "        folds_cu = cudf.DataFrame(folds)\n",
    "        \n",
    "    return folds, folds_cu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "single-variation",
   "metadata": {
    "papermill": {
     "duration": 0.022682,
     "end_time": "2021-05-01T13:34:29.117523",
     "exception": false,
     "start_time": "2021-05-01T13:34:29.094841",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "wicked-stanley",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-01T13:34:29.171332Z",
     "iopub.status.busy": "2021-05-01T13:34:29.170439Z",
     "iopub.status.idle": "2021-05-01T13:34:29.174286Z",
     "shell.execute_reply": "2021-05-01T13:34:29.173680Z"
    },
    "papermill": {
     "duration": 0.033368,
     "end_time": "2021-05-01T13:34:29.174457",
     "exception": false,
     "start_time": "2021-05-01T13:34:29.141089",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.file_paths = df['file_path'].values\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        file_path = self.file_paths[idx]\n",
    "        image = cv2.imread(file_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image)\n",
    "            image = augmented['image']\n",
    "            \n",
    "        return image, torch.tensor(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "indirect-hollywood",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-01T13:34:29.230004Z",
     "iopub.status.busy": "2021-05-01T13:34:29.229078Z",
     "iopub.status.idle": "2021-05-01T13:34:29.231981Z",
     "shell.execute_reply": "2021-05-01T13:34:29.232676Z"
    },
    "papermill": {
     "duration": 0.034736,
     "end_time": "2021-05-01T13:34:29.232818",
     "exception": false,
     "start_time": "2021-05-01T13:34:29.198082",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TestDataset_BERT(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = self.df.iloc[idx]['title']\n",
    "        text = tokenizer(text, padding='max_length', truncation=True, max_length=64, return_tensors='pt')  # 'pt': pytorch\n",
    "        input_ids = text['input_ids'][0]\n",
    "        attention_mask = text['attention_mask'][0]\n",
    "        return input_ids, attention_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sharing-stephen",
   "metadata": {
    "papermill": {
     "duration": 0.02401,
     "end_time": "2021-05-01T13:34:29.280448",
     "exception": false,
     "start_time": "2021-05-01T13:34:29.256438",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "loved-butterfly",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-01T13:34:29.333885Z",
     "iopub.status.busy": "2021-05-01T13:34:29.333042Z",
     "iopub.status.idle": "2021-05-01T13:34:29.336516Z",
     "shell.execute_reply": "2021-05-01T13:34:29.336007Z"
    },
    "papermill": {
     "duration": 0.03313,
     "end_time": "2021-05-01T13:34:29.336655",
     "exception": false,
     "start_time": "2021-05-01T13:34:29.303525",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Transforms\n",
    "# ====================================================\n",
    "def get_transforms(*, data):\n",
    "    \n",
    "    if data == 'train':\n",
    "        return Compose([\n",
    "            #Resize(CFG.size, CFG.size),\n",
    "            RandomResizedCrop(CFG.size, CFG.size),\n",
    "            Transpose(p=0.5),\n",
    "            HorizontalFlip(p=0.5),\n",
    "            VerticalFlip(p=0.5),\n",
    "            ShiftScaleRotate(p=0.5),\n",
    "            Normalize(\n",
    "                mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225],\n",
    "            ),\n",
    "            ToTensorV2(),\n",
    "        ])\n",
    "    \n",
    "    elif data == 'valid':\n",
    "        return Compose([\n",
    "            Resize(CFG.size, CFG.size),\n",
    "            Normalize(\n",
    "                mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225],\n",
    "            ),\n",
    "            ToTensorV2(),\n",
    "        ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "individual-technology",
   "metadata": {
    "papermill": {
     "duration": 0.022548,
     "end_time": "2021-05-01T13:34:29.382003",
     "exception": false,
     "start_time": "2021-05-01T13:34:29.359455",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "transsexual-pharmacy",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-01T13:34:29.440118Z",
     "iopub.status.busy": "2021-05-01T13:34:29.439035Z",
     "iopub.status.idle": "2021-05-01T13:34:29.442687Z",
     "shell.execute_reply": "2021-05-01T13:34:29.442138Z"
    },
    "papermill": {
     "duration": 0.038195,
     "end_time": "2021-05-01T13:34:29.442813",
     "exception": false,
     "start_time": "2021-05-01T13:34:29.404618",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ArcMarginProduct(nn.Module):\n",
    "    def __init__(self, in_features, out_features, scale=30.0, margin=0.50, easy_margin=False, ls_eps=0.0):\n",
    "        super(ArcMarginProduct, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.scale = scale\n",
    "        self.margin = margin\n",
    "        self.ls_eps = ls_eps\n",
    "        self.weight = nn.Parameter(torch.FloatTensor(out_features, in_features))\n",
    "        nn.init.xavier_uniform_(self.weight)\n",
    "\n",
    "        self.easy_margin = easy_margin\n",
    "        self.cos_m = math.cos(margin)\n",
    "        self.sin_m = math.sin(margin)\n",
    "        self.th = math.cos(math.pi - margin)\n",
    "        self.mm = math.sin(math.pi - margin) * margin\n",
    "        \n",
    "    def forward(self, input, label):\n",
    "        cosine = F.linear(F.normalize(input), F.normalize(self.weight))\n",
    "        sine = torch.sqrt(1.0 - torch.pow(cosine, 2))\n",
    "        phi = cosine * self.cos_m - sine * self.sin_m\n",
    "        if self.easy_margin:\n",
    "            phi = torch.where(cosine > 0, phi, cosine)\n",
    "        else:\n",
    "            phi = torch.where(cosine > self.th, phi, cosine - self.mm)\n",
    "    \n",
    "        one_hot = torch.zeros(cosine.size(), device='cuda')\n",
    "        one_hot.scatter_(1, label.view(-1, 1).long(), 1)\n",
    "        if self.ls_eps > 0:\n",
    "            one_hot = (1 - self.ls_eps) * one_hot + self.ls_eps / self.out_features\n",
    "\n",
    "        output = (one_hot * phi) + ((1.0 - one_hot) * cosine)\n",
    "        output *= self.scale\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "optical-tissue",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-01T13:34:29.498901Z",
     "iopub.status.busy": "2021-05-01T13:34:29.497783Z",
     "iopub.status.idle": "2021-05-01T13:34:29.526154Z",
     "shell.execute_reply": "2021-05-01T13:34:29.527359Z"
    },
    "papermill": {
     "duration": 0.062245,
     "end_time": "2021-05-01T13:34:29.527653",
     "exception": false,
     "start_time": "2021-05-01T13:34:29.465408",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CustomSEResNet152D(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_classes = CFG.target_size,\n",
    "        model_name = CFG.model_name_cnn,\n",
    "        fc_dim = CFG.fc_dim,\n",
    "        margin = CFG.margin,\n",
    "        scale = CFG.scale,\n",
    "        use_fc = True,\n",
    "        pretrained = True):\n",
    "        \n",
    "        super(CustomSEResNet152D, self).__init__()\n",
    "        print(f'Building Model Backbone for {model_name} model')\n",
    "        self.backbone = timm.create_model(model_name, pretrained=pretrained)\n",
    "        in_features = self.backbone.fc.in_features\n",
    "        self.backbone.fc = nn.Identity()\n",
    "        self.backbone.global_pool = nn.Identity()\n",
    "        self.pooling = nn.AdaptiveAvgPool2d(1)\n",
    "        self.use_fc = use_fc\n",
    "        \n",
    "        if use_fc:\n",
    "            self.dropout = nn.Dropout(p=0.1)\n",
    "            self.fc = nn.Linear(in_features, fc_dim)\n",
    "            self.bn = nn.BatchNorm1d(fc_dim)\n",
    "            self._init_params()\n",
    "            in_features = fc_dim\n",
    "        \n",
    "        self.final = ArcMarginProduct(\n",
    "            in_features,\n",
    "            n_classes,\n",
    "            scale = scale,\n",
    "            margin = margin,\n",
    "            easy_margin = False,\n",
    "            ls_eps = 0.0\n",
    "        )\n",
    "    \n",
    "    def _init_params(self):\n",
    "        nn.init.xavier_normal_(self.fc.weight)\n",
    "        nn.init.constant_(self.fc.bias, 0)\n",
    "        nn.init.constant_(self.bn.weight, 1)\n",
    "        nn.init.constant_(self.bn.bias, 0)\n",
    "        \n",
    "    def forward(self, image, label):\n",
    "        features = self.extract_features(image)\n",
    "        if self.training:\n",
    "            logits = self.final(features, label)\n",
    "            return logits\n",
    "        else:\n",
    "            return features\n",
    "        \n",
    "    def extract_features(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        x = self.backbone(x)\n",
    "        x = self.pooling(x).view(batch_size, -1)\n",
    "        \n",
    "        if self.use_fc:\n",
    "            x = self.dropout(x)\n",
    "            x = self.fc(x)\n",
    "            x = self.bn(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "commercial-hamburg",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-01T13:34:29.650051Z",
     "iopub.status.busy": "2021-05-01T13:34:29.649144Z",
     "iopub.status.idle": "2021-05-01T13:34:29.660035Z",
     "shell.execute_reply": "2021-05-01T13:34:29.661208Z"
    },
    "papermill": {
     "duration": 0.082202,
     "end_time": "2021-05-01T13:34:29.661424",
     "exception": false,
     "start_time": "2021-05-01T13:34:29.579222",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CustomBERT(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_classes = CFG.target_size,\n",
    "        model_name = CFG.model_name_bert,\n",
    "        fc_dim = CFG.fc_dim,\n",
    "        margin = CFG.margin,\n",
    "        scale = CFG.scale,\n",
    "        use_fc = False,\n",
    "        use_arcface = True,\n",
    "        pretrained = True):\n",
    "        \n",
    "        super(CustomBERT, self).__init__()\n",
    "        print(f'Building Model Backbone for {model_name} model')\n",
    "        self.bert = transformers.AutoModel.from_pretrained(model_name)\n",
    "        in_features = self.bert.config.hidden_size\n",
    "        self.use_fc = use_fc\n",
    "        self.use_arcface = use_arcface\n",
    "        \n",
    "        if self.use_fc:\n",
    "            self.dropout = nn.Dropout(p=0.1)\n",
    "            self.classifier = nn.Linear(in_features, fc_dim)\n",
    "            self.bn = nn.BatchNorm1d(fc_dim)\n",
    "            self._init_params()\n",
    "            in_features = fc_dim\n",
    "        \n",
    "        if self.use_arcface:\n",
    "            self.final = ArcMarginProduct(\n",
    "            in_features,\n",
    "            n_classes,\n",
    "            scale = scale,\n",
    "            margin = margin,\n",
    "            easy_margin = False,\n",
    "            ls_eps = 0.0\n",
    "        )\n",
    "        else:\n",
    "            self.final = nn.Linear(in_features, n_classes)\n",
    "    \n",
    "    def _init_params(self):\n",
    "        nn.init.xavier_normal_(self.classifier.weight)\n",
    "        nn.init.constant_(self.classifier.bias, 0)\n",
    "        nn.init.constant_(self.bn.weight, 1)\n",
    "        nn.init.constant_(self.bn.bias, 0)\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        features = self.extract_features(input_ids, attention_mask)\n",
    "        return features\n",
    "        \n",
    "    def extract_features(self, input_ids, attention_mask):\n",
    "        x = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        features = x[0]\n",
    "        features = features[:, 0, :]\n",
    "        \n",
    "        if self.use_fc:\n",
    "            features = self.dropout(features)\n",
    "            features = self.classifier(features)\n",
    "            features = self.bn(features)\n",
    "        return features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "atmospheric-arctic",
   "metadata": {
    "papermill": {
     "duration": 0.038071,
     "end_time": "2021-05-01T13:34:29.738439",
     "exception": false,
     "start_time": "2021-05-01T13:34:29.700368",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## inference functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "great-edmonton",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-01T13:34:29.827400Z",
     "iopub.status.busy": "2021-05-01T13:34:29.826265Z",
     "iopub.status.idle": "2021-05-01T13:34:29.835241Z",
     "shell.execute_reply": "2021-05-01T13:34:29.835982Z"
    },
    "papermill": {
     "duration": 0.06054,
     "end_time": "2021-05-01T13:34:29.836303",
     "exception": false,
     "start_time": "2021-05-01T13:34:29.775763",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_image_embeddings_train(folds, fold):\n",
    "    \n",
    "    model = CustomSEResNet152D(pretrained=False).to(device)\n",
    "    model_path = f'../input/shopee-009-seresnet152d-local/seresnet152d_fold{fold}_best.pth'\n",
    "    model.load_state_dict(torch.load(model_path)['model'])\n",
    "    model.eval()\n",
    "    \n",
    "    image_dataset = TestDataset(folds, transform=get_transforms(data='valid'))\n",
    "    image_loader = DataLoader(image_dataset,\n",
    "                              batch_size=CFG.batch_size,\n",
    "                              num_workers=CFG.num_workers,\n",
    "                              pin_memory=True,\n",
    "                              drop_last=False)\n",
    "    embeds = []\n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(image_loader, total=len(image_loader))\n",
    "        for img, label in pbar:\n",
    "            img = img.to(device)\n",
    "            label = label.to(device)\n",
    "            features = model(img, label)\n",
    "            image_embeddings = features.detach().cpu().numpy()\n",
    "            embeds.append(image_embeddings)\n",
    "            \n",
    "    del model\n",
    "    image_embeddings = np.concatenate(embeds)\n",
    "    print(f'Our image embeddings shape is {image_embeddings.shape}')\n",
    "    del embeds\n",
    "    gc.collect()\n",
    "    return image_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "minimal-egyptian",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-01T13:34:29.931144Z",
     "iopub.status.busy": "2021-05-01T13:34:29.930088Z",
     "iopub.status.idle": "2021-05-01T13:34:29.941609Z",
     "shell.execute_reply": "2021-05-01T13:34:29.942806Z"
    },
    "papermill": {
     "duration": 0.065159,
     "end_time": "2021-05-01T13:34:29.943032",
     "exception": false,
     "start_time": "2021-05-01T13:34:29.877873",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_image_embeddings_infer(folds, fold):\n",
    "    \n",
    "    models = []\n",
    "    for fold in CFG.trn_fold:\n",
    "        CFG.target_size = CFG.target_size_list[fold]\n",
    "        model = CustomSEResNet152D(n_classes=CFG.target_size, pretrained=False).to(device)\n",
    "        model_path = f'../input/shopee-009-seresnet152d-local/seresnet152d_fold{fold}_best.pth'\n",
    "        model.load_state_dict(torch.load(model_path)['model'])\n",
    "        model.eval()\n",
    "        models.append(model)\n",
    "    \n",
    "    image_dataset = TestDataset(folds, transform=get_transforms(data='valid'))\n",
    "    image_loader = DataLoader(image_dataset,\n",
    "                              batch_size=CFG.batch_size,\n",
    "                              num_workers=CFG.num_workers,\n",
    "                              pin_memory=True,\n",
    "                              drop_last=False)\n",
    "    embeds = []\n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(image_loader, total=len(image_loader))\n",
    "        for img, label in pbar:\n",
    "            img = img.to(device)\n",
    "            label = label.to(device)\n",
    "            image_embeddings = []\n",
    "            for model in models:\n",
    "                features_ = model(img, label)\n",
    "                image_embeddings.append(features_.detach().cpu().numpy())\n",
    "            embeds.append(np.mean(image_embeddings, axis=0))\n",
    "            \n",
    "    del model\n",
    "    image_embeddings = np.concatenate(embeds)\n",
    "    print(f'Our image embeddings shape is {image_embeddings.shape}')\n",
    "    del embeds\n",
    "    gc.collect()\n",
    "    return image_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "emerging-commissioner",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-01T13:34:30.039207Z",
     "iopub.status.busy": "2021-05-01T13:34:30.038198Z",
     "iopub.status.idle": "2021-05-01T13:34:30.046512Z",
     "shell.execute_reply": "2021-05-01T13:34:30.047265Z"
    },
    "papermill": {
     "duration": 0.053856,
     "end_time": "2021-05-01T13:34:30.047572",
     "exception": false,
     "start_time": "2021-05-01T13:34:29.993716",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_text_embeddings(folds, fold):\n",
    "    \n",
    "    model = CustomBERT(pretrained=False).to(device)\n",
    "    model_path = f'../input/hopee-004-bert-training-data/paraphrase-xlm-r-multilingual-v1_fold{fold}_best.pth'\n",
    "    model.load_state_dict(torch.load(model_path)['model'])\n",
    "    model.eval()\n",
    "    \n",
    "    text_dataset = TestDataset_BERT(folds)\n",
    "    text_loader = DataLoader(text_dataset,\n",
    "                              batch_size=CFG.batch_size,\n",
    "                              num_workers=CFG.num_workers,\n",
    "                              pin_memory=True,\n",
    "                              drop_last=False)\n",
    "    embeds = []\n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(text_loader, total=len(text_loader))\n",
    "        for input_ids, attention_mask in pbar:\n",
    "            input_ids = input_ids.to(device)\n",
    "            attention_mask = attention_mask.to(device)\n",
    "            features = model(input_ids, attention_mask)\n",
    "            text_embeddings = features.detach().cpu().numpy()\n",
    "            embeds.append(text_embeddings)\n",
    "            \n",
    "    del model\n",
    "    text_embeddings = np.concatenate(embeds)\n",
    "    print(f'Our text embeddings shape is {text_embeddings.shape}')\n",
    "    del embeds\n",
    "    gc.collect()\n",
    "    return text_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "criminal-sympathy",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-01T13:34:30.137750Z",
     "iopub.status.busy": "2021-05-01T13:34:30.136882Z",
     "iopub.status.idle": "2021-05-01T13:34:30.141863Z",
     "shell.execute_reply": "2021-05-01T13:34:30.142925Z"
    },
    "papermill": {
     "duration": 0.054842,
     "end_time": "2021-05-01T13:34:30.143163",
     "exception": false,
     "start_time": "2021-05-01T13:34:30.088321",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_text_predictions(df, df_cu, max_features=25_000):\n",
    "    \n",
    "    model = TfidfVectorizer(stop_words='english',\n",
    "                            binary=True,\n",
    "                            max_features=max_features)\n",
    "    text_embeddings = model.fit_transform(df_cu['title']).toarray()\n",
    "    \n",
    "    print('Finding similar titles...')\n",
    "    CHUNK = 1024 * 4\n",
    "    CTS = len(df) // CHUNK\n",
    "    if (len(df)%CHUNK) != 0:\n",
    "        CTS += 1\n",
    "        \n",
    "    preds = []\n",
    "    for j in range( CTS ):\n",
    "        a = j * CHUNK\n",
    "        b = (j+1) * CHUNK\n",
    "        b = min(b, len(df))\n",
    "        print('chunk', a, 'to', b)\n",
    "        \n",
    "        # COSINE SIMILARITY DISTANCE\n",
    "        cts = cupy.matmul(text_embeddings, text_embeddings[a:b].T).T\n",
    "        \n",
    "        for k in range(b-a):\n",
    "            IDX = cupy.where(cts[k,]>0.75)[0]  # 変える余地がありそう\n",
    "            o = df.iloc[cupy.asnumpy(IDX)].posting_id.values\n",
    "            preds.append(o)\n",
    "            \n",
    "    del model, text_embeddings\n",
    "    gc.collect()\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "front-hours",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-01T13:34:30.238858Z",
     "iopub.status.busy": "2021-05-01T13:34:30.237851Z",
     "iopub.status.idle": "2021-05-01T13:34:30.246433Z",
     "shell.execute_reply": "2021-05-01T13:34:30.247673Z"
    },
    "papermill": {
     "duration": 0.062967,
     "end_time": "2021-05-01T13:34:30.247887",
     "exception": false,
     "start_time": "2021-05-01T13:34:30.184920",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_neighbors(df, embeddings, KNN = 50, image = True, cnn_thresh=0.4):\n",
    "    \n",
    "    model = NearestNeighbors(n_neighbors = KNN, metric='cosine')\n",
    "    model.fit(embeddings)\n",
    "    distances, indices = model.kneighbors(embeddings)\n",
    "    \n",
    "    # Iterate through different thresholds to maximize cv, run this in interactive mode, then replace else clause with a solid threshold\n",
    "    if CFG.GET_CV:\n",
    "#         if image:\n",
    "#             thresholds = list(np.arange(0.3, 0.6, 0.01))\n",
    "#         else:\n",
    "#             thresholds = list(np.arange(0.1, 1, 0.05))  # changed\n",
    "#         scores = []\n",
    "#         for threshold in thresholds:\n",
    "#             predictions = []\n",
    "#             for k in range(embeddings.shape[0]):\n",
    "#                 idx = np.where(distances[k,] < threshold)[0]\n",
    "#                 ids = indices[k, idx]\n",
    "#                 posting_ids = ' '.join(df['posting_id'].iloc[ids].values)\n",
    "#                 predictions.append(posting_ids)\n",
    "#             df['pred_matches'] = predictions\n",
    "#             df['f1'] = f1_score(df['matches'], df['pred_matches'])\n",
    "#             score = df['f1'].mean()\n",
    "#             print(f'Our f1 score for threshold {threshold} is {score}')\n",
    "#             scores.append(score)\n",
    "#         thresholds_scores = pd.DataFrame({'thresholds': thresholds, 'scores': scores})\n",
    "#         max_score = thresholds_scores[thresholds_scores['scores'] == thresholds_scores['scores'].max()]\n",
    "#         best_threshold  = max_score['thresholds'].values[0]\n",
    "#         best_score = max_score['scores'].values[0]\n",
    "#         print(f'Our best score is {best_score} and has a threshold {best_threshold}')\n",
    "        \n",
    "        # Use threshold\n",
    "        predictions = []\n",
    "        for k in range(embeddings.shape[0]):\n",
    "            # Because we are predicting the test set that have 70K images and different label groups, confidence should be smaller\n",
    "            if image:\n",
    "                idx = np.where(distances[k,] < cnn_thresh)[0]\n",
    "            else:\n",
    "                idx = np.where(distances[k,] < 0.3)[0]\n",
    "            ids = indices[k, idx]\n",
    "            posting_ids = df['posting_id'].iloc[ids].values\n",
    "            predictions.append(posting_ids)\n",
    "            \n",
    "    # Because we are predicting the test set that have 70K images and different label groups, confidence should be smaller\n",
    "    else:\n",
    "        predictions = []\n",
    "        for k in tqdm(range(embeddings.shape[0])):\n",
    "            if image:\n",
    "                idx = np.where(distances[k,] < cnn_thresh)[0]\n",
    "            else:\n",
    "                idx = np.where(distances[k,] < 0.3)[0]\n",
    "            ids = indices[k,idx]\n",
    "            posting_ids = df['posting_id'].iloc[ids].values\n",
    "            predictions.append(posting_ids)\n",
    "        \n",
    "    del model, distances, indices\n",
    "    gc.collect()\n",
    "    return df, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "heavy-complaint",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-01T13:34:30.340563Z",
     "iopub.status.busy": "2021-05-01T13:34:30.339546Z",
     "iopub.status.idle": "2021-05-01T13:34:30.370693Z",
     "shell.execute_reply": "2021-05-01T13:34:30.371890Z"
    },
    "papermill": {
     "duration": 0.083177,
     "end_time": "2021-05-01T13:34:30.372160",
     "exception": false,
     "start_time": "2021-05-01T13:34:30.288983",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def match_algo_interpolation_train(submit_df):\n",
    "    match_dic = {}\n",
    "    \n",
    "    def count_match(row):\n",
    "        return len(row[\"pred_matches\"].split())-1\n",
    "    \n",
    "    def match_diff(row):\n",
    "        posting_id = np.array(row[\"posting_id\"])\n",
    "        pred_matches = np.array(row[\"pred_matches\"].split())\n",
    "        pred_match = np.array(np.setdiff1d(pred_matches, posting_id)).tolist()\n",
    "        if row[\"match_num\"] > 0:\n",
    "            return \" \".join(pred_match)\n",
    "        else:\n",
    "            return\n",
    "\n",
    "    def get_match_dic(row):\n",
    "        if row[\"match_num\"] > 0:\n",
    "            if not match_dic.get(row[\"pred_match\"]):\n",
    "                match_dic[row[\"pred_match\"]] = [row[\"posting_id\"]]\n",
    "            else:\n",
    "                match_dic[row[\"pred_match\"]].append(row[\"posting_id\"])\n",
    "\n",
    "    def join_list():\n",
    "        for k, v in match_dic.items():\n",
    "            match_dic[k] = \" \".join(v)\n",
    "\n",
    "    def column_merge(row):\n",
    "        if row[\"match_num\"] > 0:\n",
    "            x = row['pred_matches'] + \" \" + row['posting_id_2']\n",
    "            x = np.array(x.split())\n",
    "            return ' '.join( np.unique(x) )\n",
    "        else:\n",
    "            return row['pred_matches']\n",
    "        \n",
    "    submit_df['match_num'] = submit_df.apply(count_match, axis=1)\n",
    "    submit_df['pred_match'] = submit_df.apply(match_diff, axis=1)\n",
    "    submit_df.apply(get_match_dic, axis=1)\n",
    "    \n",
    "    join_list()\n",
    "    match_df = pd.DataFrame.from_dict(match_dic, orient='index')\n",
    "    match_df = match_df.reset_index()\n",
    "    match_df = match_df.rename(columns = {'index': 'pred_match', 0: 'posting_id_2'}, inplace = False)\n",
    "    \n",
    "    submit_df = pd.merge(submit_df, match_df, on='pred_match', how='left')\n",
    "    submit_df[\"pred_matches_2\"] = submit_df.apply(column_merge, axis=1)\n",
    "    \n",
    "    submit_df['f1_1'] = f1_score(submit_df['matches'], submit_df['pred_matches'])\n",
    "    submit_df['f1_2'] = f1_score(submit_df['matches'], submit_df['pred_matches_2'])\n",
    "\n",
    "    score_1 = submit_df['f1_1'].mean()\n",
    "    score_2 = submit_df['f1_2'].mean()\n",
    "\n",
    "    print(f'Our final f1 origin cv score is {score_1}')\n",
    "    print(f'Our final f1 match algo cv score is {score_2}')\n",
    "    \n",
    "    submit_df_2 = pd.DataFrame()\n",
    "    submit_df_2[['posting_id', 'pred_matches']] = submit_df[['posting_id', 'pred_matches_2']]\n",
    "    return submit_df_2\n",
    "\n",
    "def match_algo_interpolation_inference(submit_df):\n",
    "    match_dic = {}\n",
    "    \n",
    "    def count_match(row):\n",
    "        return len(row[\"matches\"].split())-1\n",
    "    \n",
    "    def match_diff(row):\n",
    "        posting_id = np.array(row[\"posting_id\"])\n",
    "        pred_matches = np.array(row[\"matches\"].split())\n",
    "        pred_match = np.array(np.setdiff1d(pred_matches, posting_id)).tolist()\n",
    "        if row[\"match_num\"] > 0:\n",
    "            return \" \".join(pred_match)\n",
    "        else:\n",
    "            return row[\"matches\"]\n",
    "\n",
    "    def get_match_dic(row):\n",
    "        if row[\"match_num\"] > 0:\n",
    "            if not match_dic.get(row[\"matches\"]):\n",
    "                match_dic[row[\"matches\"]] = [row[\"posting_id\"]]\n",
    "            else:\n",
    "                match_dic[row[\"matches\"]].append(row[\"posting_id\"])\n",
    "\n",
    "    def join_list():\n",
    "        for k, v in match_dic.items():\n",
    "            match_dic[k] = \" \".join(v)\n",
    "\n",
    "    def column_merge(row):\n",
    "        if row[\"match_num\"] > 0:\n",
    "            x = row['matches'] + \" \" + row['posting_id_2']\n",
    "            x = np.array(x.split())\n",
    "            return ' '.join( np.unique(x) )\n",
    "        else:\n",
    "            return row['matches']\n",
    "        \n",
    "    submit_df['match_num'] = submit_df.apply(count_match, axis=1)\n",
    "    submit_df['matches'] = submit_df.apply(match_diff, axis=1)\n",
    "    submit_df.apply(get_match_dic, axis=1)\n",
    "    \n",
    "    join_list()\n",
    "    match_df = pd.DataFrame.from_dict(match_dic, orient='index')\n",
    "    match_df = match_df.reset_index()\n",
    "    match_df = match_df.rename(columns = {'index': 'matches', 0: 'posting_id_2'}, inplace = False)\n",
    "    \n",
    "    submit_df = pd.merge(submit_df, match_df, on='matches', how='left')\n",
    "    submit_df[\"pred_matches_2\"] = submit_df.apply(column_merge, axis=1)\n",
    "    \n",
    "    submit_df_2 = pd.DataFrame()\n",
    "    submit_df_2[['posting_id', 'matches']] = submit_df[['posting_id', 'pred_matches_2']]\n",
    "    return submit_df_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electric-collector",
   "metadata": {
    "papermill": {
     "duration": 0.03882,
     "end_time": "2021-05-01T13:34:30.451858",
     "exception": false,
     "start_time": "2021-05-01T13:34:30.413038",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Calculating Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "organized-explorer",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-01T13:34:30.537066Z",
     "iopub.status.busy": "2021-05-01T13:34:30.536148Z",
     "iopub.status.idle": "2021-05-01T13:34:40.273670Z",
     "shell.execute_reply": "2021-05-01T13:34:40.273075Z"
    },
    "papermill": {
     "duration": 9.783138,
     "end_time": "2021-05-01T13:34:40.273811",
     "exception": false,
     "start_time": "2021-05-01T13:34:30.490673",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fold\n",
       "0    6851\n",
       "1    6849\n",
       "2    6850\n",
       "3    6850\n",
       "4    6850\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>posting_id</th>\n",
       "      <th>image</th>\n",
       "      <th>image_phash</th>\n",
       "      <th>title</th>\n",
       "      <th>label_group</th>\n",
       "      <th>fold</th>\n",
       "      <th>matches</th>\n",
       "      <th>file_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_129225211</td>\n",
       "      <td>0000a68812bc7e98c42888dfb1c07da0.jpg</td>\n",
       "      <td>94974f937d4c2433</td>\n",
       "      <td>Paper Bag Victoria Secret</td>\n",
       "      <td>249114794</td>\n",
       "      <td>3</td>\n",
       "      <td>train_129225211 train_2278313361</td>\n",
       "      <td>../input/shopee-product-matching/train_images/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_3386243561</td>\n",
       "      <td>00039780dfc94d01db8676fe789ecd05.jpg</td>\n",
       "      <td>af3f9460c2838f0f</td>\n",
       "      <td>Double Tape 3M VHB 12 mm x 4,5 m ORIGINAL / DO...</td>\n",
       "      <td>2937985045</td>\n",
       "      <td>3</td>\n",
       "      <td>train_3386243561 train_3423213080</td>\n",
       "      <td>../input/shopee-product-matching/train_images/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_2288590299</td>\n",
       "      <td>000a190fdd715a2a36faed16e2c65df7.jpg</td>\n",
       "      <td>b94cb00ed3e50f78</td>\n",
       "      <td>Maling TTS Canned Pork Luncheon Meat 397 gr</td>\n",
       "      <td>2395904891</td>\n",
       "      <td>4</td>\n",
       "      <td>train_2288590299 train_3803689425</td>\n",
       "      <td>../input/shopee-product-matching/train_images/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_2406599165</td>\n",
       "      <td>00117e4fc239b1b641ff08340b429633.jpg</td>\n",
       "      <td>8514fc58eafea283</td>\n",
       "      <td>Daster Batik Lengan pendek - Motif Acak / Camp...</td>\n",
       "      <td>4093212188</td>\n",
       "      <td>3</td>\n",
       "      <td>train_2406599165 train_3342059966</td>\n",
       "      <td>../input/shopee-product-matching/train_images/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_3369186413</td>\n",
       "      <td>00136d1cf4edede0203f32f05f660588.jpg</td>\n",
       "      <td>a6f319f924ad708c</td>\n",
       "      <td>Nescafe \\xc3\\x89clair Latte 220ml</td>\n",
       "      <td>3648931069</td>\n",
       "      <td>1</td>\n",
       "      <td>train_3369186413 train_921438619</td>\n",
       "      <td>../input/shopee-product-matching/train_images/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         posting_id                                 image       image_phash  \\\n",
       "0   train_129225211  0000a68812bc7e98c42888dfb1c07da0.jpg  94974f937d4c2433   \n",
       "1  train_3386243561  00039780dfc94d01db8676fe789ecd05.jpg  af3f9460c2838f0f   \n",
       "2  train_2288590299  000a190fdd715a2a36faed16e2c65df7.jpg  b94cb00ed3e50f78   \n",
       "3  train_2406599165  00117e4fc239b1b641ff08340b429633.jpg  8514fc58eafea283   \n",
       "4  train_3369186413  00136d1cf4edede0203f32f05f660588.jpg  a6f319f924ad708c   \n",
       "\n",
       "                                               title  label_group  fold  \\\n",
       "0                          Paper Bag Victoria Secret    249114794     3   \n",
       "1  Double Tape 3M VHB 12 mm x 4,5 m ORIGINAL / DO...   2937985045     3   \n",
       "2        Maling TTS Canned Pork Luncheon Meat 397 gr   2395904891     4   \n",
       "3  Daster Batik Lengan pendek - Motif Acak / Camp...   4093212188     3   \n",
       "4                  Nescafe \\xc3\\x89clair Latte 220ml   3648931069     1   \n",
       "\n",
       "                             matches  \\\n",
       "0   train_129225211 train_2278313361   \n",
       "1  train_3386243561 train_3423213080   \n",
       "2  train_2288590299 train_3803689425   \n",
       "3  train_2406599165 train_3342059966   \n",
       "4   train_3369186413 train_921438619   \n",
       "\n",
       "                                           file_path  \n",
       "0  ../input/shopee-product-matching/train_images/...  \n",
       "1  ../input/shopee-product-matching/train_images/...  \n",
       "2  ../input/shopee-product-matching/train_images/...  \n",
       "3  ../input/shopee-product-matching/train_images/...  \n",
       "4  ../input/shopee-product-matching/train_images/...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folds, folds_cu = read_dataset()\n",
    "folds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aggressive-livestock",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-01T13:34:40.341579Z",
     "iopub.status.busy": "2021-05-01T13:34:40.340641Z",
     "iopub.status.idle": "2021-05-01T13:39:34.998841Z",
     "shell.execute_reply": "2021-05-01T13:39:34.999442Z"
    },
    "papermill": {
     "duration": 294.698875,
     "end_time": "2021-05-01T13:39:34.999642",
     "exception": false,
     "start_time": "2021-05-01T13:34:40.300767",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Model Backbone for seresnet152d model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4d57cfd60244693af3a54d9d418510f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/215 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our image embeddings shape is (6851, 512)\n",
      "Building Model Backbone for ../input/sentence-transformer-models/paraphrase-xlm-r-multilingual-v1/0_Transformer model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe58a0dee02d4b4cb765cc4904c8d654",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/215 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our text embeddings shape is (6851, 768)\n",
      "Finding similar titles...\n",
      "chunk 0 to 4096\n",
      "chunk 4096 to 6851\n",
      "Our final f1 cv score for thresh 0.3 is 0.8025058400346566\n",
      "Our final f1 cv score for thresh 0.31 is 0.8056145148173011\n",
      "Our final f1 cv score for thresh 0.32 is 0.8089542567415082\n",
      "Our final f1 cv score for thresh 0.33 is 0.8106348953119762\n",
      "Our final f1 cv score for thresh 0.34 is 0.8135879917618233\n",
      "Our final f1 cv score for thresh 0.35000000000000003 is 0.8157518920662553\n",
      "Our final f1 cv score for thresh 0.36000000000000004 is 0.8183657610686983\n",
      "Our final f1 cv score for thresh 0.37000000000000005 is 0.8207152863246251\n",
      "Our final f1 cv score for thresh 0.38000000000000006 is 0.8229697954988104\n",
      "Our final f1 cv score for thresh 0.39000000000000007 is 0.8255918784744221\n",
      "Our final f1 cv score for thresh 0.4000000000000001 is 0.8282251666867424\n",
      "Our final f1 cv score for thresh 0.3 is 0.8025058400346566\n",
      "Our final f1 origin cv score is 0.8025058400346566\n",
      "Our final f1 match algo cv score is 0.8065319418818051\n"
     ]
    }
   ],
   "source": [
    "# Get neighbors for image_embeddings\n",
    "if CFG.GET_CV:\n",
    "    # fold0のみのCVを算出する\n",
    "    folds_= folds[folds['fold'] == 0]\n",
    "    folds_cu_ = folds_cu[folds['fold'] == 0]\n",
    "    image_embeddings = get_image_embeddings_train(folds_, fold=0)\n",
    "    text_embeddings = get_text_embeddings(folds_, fold=0)\n",
    "    text_predictions_tfidf = get_text_predictions(folds_, folds_cu_, max_features=25_000)\n",
    "        \n",
    "    # 複数のthresholdに対してCVを算出する\n",
    "    for thresh in list(np.arange(0.3, 0.4, 0.01)) + [0.3]:\n",
    "        oof_df, image_predictions = get_neighbors(folds_, image_embeddings, KNN=50 if len(folds)>3 else 3, image=True, cnn_thresh=thresh)\n",
    "        oof_df, text_predictions_bert = get_neighbors(folds_, text_embeddings, KNN=50 if len(folds) > 3 else 3, image=False)\n",
    "        oof_df['image_predictions'] = image_predictions\n",
    "        oof_df['text_predictions_tfidf'] = text_predictions_tfidf\n",
    "        oof_df['text_predictions_bert'] = text_predictions_bert\n",
    "        oof_df['text_predictions_bert_len'] = oof_df['text_predictions_bert'].apply(lambda x: len(x))\n",
    "        oof_df['text_predictions'] = oof_df['text_predictions_tfidf'].mask(oof_df['text_predictions_bert_len'] == 2, oof_df['text_predictions_bert'])\n",
    "        oof_df['pred_matches'] = oof_df.apply(combine_predictions, axis = 1)\n",
    "        oof_df['f1'] = f1_score(oof_df['matches'], oof_df['pred_matches'])\n",
    "        score = oof_df['f1'].mean()\n",
    "        print(f'Our final f1 cv score for thresh {thresh} is {score}')\n",
    "            \n",
    "    oof_df.to_pickle('oof_df.pkl')\n",
    "    oof_df = match_algo_interpolation_train(oof_df)\n",
    "    oof_df[['posting_id', 'pred_matches']].to_csv('submission.csv', index = False)\n",
    "    \n",
    "else:\n",
    "    image_embeddings = get_image_embeddings_infer(folds, fold=0)\n",
    "    text_embeddings = get_text_embeddings(folds, fold=0)\n",
    "    df, image_predictions = get_neighbors(folds, image_embeddings, KNN=50 if len(folds)>3 else 3, image=True, cnn_thresh=0.3)\n",
    "    text_predictions_tfidf = get_text_predictions(folds, folds_cu, max_features=25_000) \n",
    "    df, text_predictions_bert = get_neighbors(folds, text_embeddings, KNN=50 if len(folds) > 3 else 3, image=False)\n",
    "    df['image_predictions'] = image_predictions\n",
    "    df['text_predictions_tfidf'] = text_predictions_tfidf\n",
    "    df['text_predictions_bert'] = text_predictions_bert\n",
    "    df['text_predictions_bert_len'] = df['text_predictions_bert'].apply(lambda x: len(x))\n",
    "    df['text_predictions'] = df['text_predictions_tfidf'].mask(df['text_predictions_bert_len'] == 2, df['text_predictions_bert'])\n",
    "    df['matches'] = df.apply(combine_predictions, axis = 1)\n",
    "    df = match_algo_interpolation_inference(df)\n",
    "    df[['posting_id', 'matches']].to_csv('submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "coordinate-graphics",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-01T13:39:35.072959Z",
     "iopub.status.busy": "2021-05-01T13:39:35.072132Z",
     "iopub.status.idle": "2021-05-01T13:39:35.095561Z",
     "shell.execute_reply": "2021-05-01T13:39:35.095039Z"
    },
    "papermill": {
     "duration": 0.0619,
     "end_time": "2021-05-01T13:39:35.095701",
     "exception": false,
     "start_time": "2021-05-01T13:39:35.033801",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>posting_id</th>\n",
       "      <th>pred_matches</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_1802986387</td>\n",
       "      <td>train_1802986387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_1598329973</td>\n",
       "      <td>train_1598329973 train_4224502769 train_841015183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_4196427721</td>\n",
       "      <td>train_2221959828 train_3757879175 train_419642...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_2985955659</td>\n",
       "      <td>train_2985955659 train_3916258742 train_415673...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_3466601092</td>\n",
       "      <td>train_3466601092 train_354147588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6846</th>\n",
       "      <td>train_259196128</td>\n",
       "      <td>train_259196128 train_3219916478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6847</th>\n",
       "      <td>train_3074398993</td>\n",
       "      <td>train_2919333796 train_3074398993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6848</th>\n",
       "      <td>train_3296417563</td>\n",
       "      <td>train_1569930350 train_3296417563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6849</th>\n",
       "      <td>train_945815402</td>\n",
       "      <td>train_945815402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6850</th>\n",
       "      <td>train_1792180725</td>\n",
       "      <td>train_1792180725 train_795128312</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6851 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            posting_id                                       pred_matches\n",
       "0     train_1802986387                                   train_1802986387\n",
       "1     train_1598329973  train_1598329973 train_4224502769 train_841015183\n",
       "2     train_4196427721  train_2221959828 train_3757879175 train_419642...\n",
       "3     train_2985955659  train_2985955659 train_3916258742 train_415673...\n",
       "4     train_3466601092                   train_3466601092 train_354147588\n",
       "...                ...                                                ...\n",
       "6846   train_259196128                   train_259196128 train_3219916478\n",
       "6847  train_3074398993                  train_2919333796 train_3074398993\n",
       "6848  train_3296417563                  train_1569930350 train_3296417563\n",
       "6849   train_945815402                                    train_945815402\n",
       "6850  train_1792180725                   train_1792180725 train_795128312\n",
       "\n",
       "[6851 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stuffed-commodity",
   "metadata": {
    "papermill": {
     "duration": 0.034706,
     "end_time": "2021-05-01T13:39:35.165484",
     "exception": false,
     "start_time": "2021-05-01T13:39:35.130778",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 327.955039,
   "end_time": "2021-05-01T13:39:38.879862",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-05-01T13:34:10.924823",
   "version": "2.3.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "124ce30d17194e199f2cf46b7003ce5e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_a21746aff6864d3d82614f9349080cc0",
       "placeholder": "​",
       "style": "IPY_MODEL_c2dd2a2d7d47477da199e5c2c646f79e",
       "value": "100%"
      }
     },
     "2d69a531e36e44e9a29f509aa7af7e61": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3978d7f7413445c4af87d1f1b96f49f9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "3a101c5b937e406e92af676af172ab02": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_6582e88d830d40cca24b15e3decdece0",
       "max": 215.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_584123bf00fd422c9faa28b658a60a11",
       "value": 215.0
      }
     },
     "492218dd351e4db982eef4be5acc0ab9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "4d8ee518f051419a8602ab37388d2962": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "567d01384a8941a797572c2eff37e85a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "584123bf00fd422c9faa28b658a60a11": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "61a7815dc6794f16aaeaecb687e68af5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6582e88d830d40cca24b15e3decdece0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "77b57975288c4777ac55187dfd35c868": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_2d69a531e36e44e9a29f509aa7af7e61",
       "placeholder": "​",
       "style": "IPY_MODEL_567d01384a8941a797572c2eff37e85a",
       "value": "100%"
      }
     },
     "806f52cbb4de4952a78f9cc0edbbab0d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "9612a972675643059bd72915172a5d27": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_4d8ee518f051419a8602ab37388d2962",
       "max": 215.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_492218dd351e4db982eef4be5acc0ab9",
       "value": 215.0
      }
     },
     "9fbe1be5490143858e68ad801ca2be7a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a21746aff6864d3d82614f9349080cc0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c18ed1f0cb104eb4a403fce63454bb9d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_ff711188dc6c4b7b9ae1d91ed2e0867b",
       "placeholder": "​",
       "style": "IPY_MODEL_806f52cbb4de4952a78f9cc0edbbab0d",
       "value": " 215/215 [03:02&lt;00:00,  1.26it/s]"
      }
     },
     "c2dd2a2d7d47477da199e5c2c646f79e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "cdbf6cedfae84e1f96b718a174c50266": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_f63bc9058a7044828402776e52619182",
       "placeholder": "​",
       "style": "IPY_MODEL_3978d7f7413445c4af87d1f1b96f49f9",
       "value": " 215/215 [00:14&lt;00:00, 15.36it/s]"
      }
     },
     "f4d57cfd60244693af3a54d9d418510f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_77b57975288c4777ac55187dfd35c868",
        "IPY_MODEL_9612a972675643059bd72915172a5d27",
        "IPY_MODEL_c18ed1f0cb104eb4a403fce63454bb9d"
       ],
       "layout": "IPY_MODEL_61a7815dc6794f16aaeaecb687e68af5"
      }
     },
     "f63bc9058a7044828402776e52619182": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "fe58a0dee02d4b4cb765cc4904c8d654": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_124ce30d17194e199f2cf46b7003ce5e",
        "IPY_MODEL_3a101c5b937e406e92af676af172ab02",
        "IPY_MODEL_cdbf6cedfae84e1f96b718a174c50266"
       ],
       "layout": "IPY_MODEL_9fbe1be5490143858e68ad801ca2be7a"
      }
     },
     "ff711188dc6c4b7b9ae1d91ed2e0867b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
